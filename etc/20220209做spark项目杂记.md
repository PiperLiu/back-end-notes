
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [将本地 jar 安装到本地 maven 仓库](#将本地-jar-安装到本地-maven-仓库)
- [Spark 训练机器学习模型莫名报错（java.lang.stackoverflow）](#spark-训练机器学习模型莫名报错javalangstackoverflow)
- [Windows 运行 hadoop](#windows-运行-hadoop)
- [在 spark pipeline 中加入已训练模型](#在-spark-pipeline-中加入已训练模型)
- [Spark 工作总结](#spark-工作总结)

<!-- /code_chunk_output -->

### 将本地 jar 安装到本地 maven 仓库

把要打包的 jar 放在本地目录下。

在 maven 中执行命令（IDEA 中可以选择 run in context ）：

```bash
mvn install:install-file
    -Dfile="jar包所在路径"
    -DgroupId="jar包的groupId"
    -DartifactId="你规定的artifactId"
    -Dversion="你规定的version"
    -Dpackaging=jar
    -Dmaven.repo.local="本地仓库路径"
```

之后便可以在 pom 中使用：

```xml
<dependency>
    <groupId>jar包的groupId</groupId>
    <artifactId>你规定的的artifactId</artifactId>
    <version>2.15.2</version>
</dependency>
```

举个例子，假设我们打包编译好了 mmlspark-1.0.0-rc2.jar ，将其放在 C 盘下面。

之后便是用 IDEA 安装。

```bash
mvn install:install-file
    -Dfile=C:\mmlspark-1.0.0-rc2.jar
    -DgroupId=com.microsoft.ml.spark
    -DartifactId=mmlspark_2.11
    -Dversion=1.0.0-rc2
    -Dpackaging=jar
    -Dmaven.repo.local=C:\tools\maven\repository
```

使用时，直接修改 pom 文件：

```xml
<dependency>
    <groupId>com.microsoft.ml.spark</groupId>
    <artifactId>mmlspark_2.11</artifactId>
    <version>1.0.0-rc2</version>
</dependency>
```

### Spark 训练机器学习模型莫名报错（java.lang.stackoverflow）

遇到一个问题，为此熬了夜，如果没遇到[这篇文章](https://botkampa.medium.com/how-to-fix-java-lang-stackoverflow-when-training-your-ml-model-in-spark-d4db3ff6af37)，很难发现原因。

具体描述一下问题，我的代码如下：

```scala
var dataDf = ...  // load from other place
val inDoubleCols = dataDf.dtypes.filter(
    _._2 != "DoubleType"
).map(_._1).toArray[String]
inDoubleCols.forearch(column => {
    dataDf = dataDf.withColumn(column, col(column).cast(DoubleType))
})

val classifier: LightGBMClassifier = new LightGBMClassifier().setFeaturesCol("features").setLabelCol("label")
val model = classifier.fit(dataDf)
```

在 fit 那句报错了，如下：

```bash
...
21/09/17 11:37:34 INFO SparkContext: Created broadcast 7 from rdd at LightGBMBase.scala:195
21/09/17 11:37:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
Exception in thread "main" java.lang.StackOverflowError
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:126)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:126)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:126)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:126)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:126)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:126)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
	...
```

很长很长，实际上就是函数把 stack （栈）给堆满了。我和另外两个前辈没见过这种情况，管这种情况叫“超级树”。

按照一般的思路，在 fit 这行报错，那我们怀疑就是 fit 内部某些机制错了，于是各种更换 scala 版本、 spark 版本、 mmlspark 版本、增加 Xms 等等配置...一直到深夜都没解决“超级树”问题。

当时并不了解 spark 运行机制。那么，问题到底出在哪里呢？

换个思路，其实但凡懂一点计算机原理、思维别太死板也能看出来， **上面的 java.lang.stackoverflow 是因为积攒了太多函数没运行。**

**为什么到了 fit 这里会积攒太多函数呢？因为 Spark 里面有“懒操作”一说：比如在 数据 dataDf 的 withColumn 这个函数被调用时，不一定要立即去做这件事，而是积攒着，直到 dataDf 需要被缓存、被展示、被计算得到新的值时，之前积攒的一些列操作才开始被调用。** 你看我前面 foreach 了那么多 withColumn ，那自然，积攒的函数就很多，就会在 fit 时 java.lang.stackoverflow 。

我当时的解决方案是加入一个 `cache()` ：

```scala
var dataDf = ...  // load from other place
val inDoubleCols = dataDf.dtypes.filter(
    _._2 != "DoubleType"
).map(_._1).toArray[String]
inDoubleCols.forearch(column => {
    dataDf = dataDf.withColumn(column, col(column).cast(DoubleType))
})

dataDf.cache()  // 把之前积攒的懒操作做一做

val classifier: LightGBMClassifier = new LightGBMClassifier().setFeaturesCol("features").setLabelCol("label")
val model = classifier.fit(dataDf)
```

现在看来，上面的代码还是太糟糕了。

既然都用函数式编程了，就不要有 `cols.forearch(c => { x = x... })` 这么愚蠢的写法。而且对每一列进行 withColumn 来转换类型是极其极其低效率的。

如果给我改，该怎么改？

```scala
var dataDf = ...  // load from other place
val doubleCols = dataDf.columns.map(
    f => col(f).cast(DoubleType)
)

dataDf.select(doubleCols: _*)
dataDf.show(1, true)  // 把之前积攒的懒操作做一做

val classifier: LightGBMClassifier = new LightGBMClassifier().setFeaturesCol("features").setLabelCol("label")
val model = classifier.fit(dataDf)
```

注意这里有两个经验，新手必须要越早知道越好：
- select 进行批量类型转换，效率远高于 withColumn
- cache 可以用，但是不能乱用；在不需要把数据传入缓存、只想清空懒操作的情况下， show 没准是更高效的选择

归根结底是当时不了解 Spark 原理。可能小厂就是这样，人手不够，需求还贼多，我连 scala 都没听说过，就接手这么庞大个 Spark 项目，也没有时间学习原理、公司里也没人会没人带我...赶鸭子上架了属于是。现在空下来了，先把原理补一补。

### Windows 运行 hadoop

```
java.io.IOException: (null) entry in command string: null chmod 0644
```

在 windows 上跑 spark 似乎不是一个好想法，因为人家 hadoop 根本就没想过要编译给非 linux 系的平台使用。

如上是最常见的一个错误，用 spark 读写文件系统时会报错。

这个很简单，去 [https://github.com/cdarlint/winutils](https://github.com/cdarlint/winutils) 这里找到你的对应版本，用其中的 bin 代替你本地的 bin 。然后配置环境变量 `%HADOOP_HOME%` 以及 `PATH+=%HADOOP_HOME%/bin`  。

在这个 [https://github.com/cdarlint/winutils](https://github.com/cdarlint/winutils) 里人家大佬手把手教你编译 hadoop 过程。

### 在 spark pipeline 中加入已训练模型（以 离散化编码 ValueIndexerModel 为例）

我们训练机器学习模型，总的来说有两个阶段：训练模型、使用（部署）模型。

在 Spark 中，假设我们的要用到的算法叫做 XXX ，那么向 XXX 输入训练数据 data 以后，将得到 XXX 对应的 Model 。如下。

```scala
val XXXModel = XXX.fit(data)
```

我们在使用模型时，使用的是 XXXModel 。即 XXXModel.transform(newData) 。

好了，基础背景介绍完毕，下面是我们的问题。

绝大部分情况下，我们要把数据流程放在一个管道 pipeline 里，比如下面这样（参考了[官网 example](https://spark.apache.org/docs/latest/ml-pipeline.html)）。

```scala
// 我们希望先用 ValueIndexer 把职业这一列离散化
// 再把特征列聚合为一个向量列，再用逻辑回归运算
val vi = new ValueIndexer().setInputCol("职业").setOutputCol("oppo")
val assembler = new VectorAssembler()
  .setInputCols(Array("age", "mobile", "oppo"))
  .setOutputCol("features")
val lr = new LogisticRegression()
  .setMaxIter(10)
  .setRegParam(0.001)
  .setFeatureCol("features")
  .setLabelCol("label")
val pipeline = new Pipeline()
  .setStages(Array(vi, assembler, lr))

// 训练数据输入管道，得到 model
val model = pipeline.fit(training)

// 测试数据输入 model ，得到结果
model.transform(test)
  .select("id", "probability", "prediction")
  .collect()
  .foreach { case Row(id: Long, prob: Vector, prediction: Double) =>
    println(s"$id --> prob=$prob, prediction=$prediction")
  }
```

OK，一切都很直观简单。那么，我现在有个需求，对于“将职业离散化”这个过程，我已经有了一套标准，该怎么办呢？

举个例子，假设有职业列有三个值：`学生`、`工作`以及`未知`。如果将离散化交给 Spark ，那么，我们可能得到 `学生0` `工作1` `未知2` 或者 `学生1` `工作2` `未知0` 等不确定的编码。现在业务上要求必须使用一套确定的编码，该怎么办呢？

解决方法很简单，把 ValueIndexerModel 取代 ValueIndexer 放在 pipeline 里就好了。如下。

```scala
// 我们希望先用 ValueIndexer 把职业这一列离散化
// 再把特征列聚合为一个向量列，再用逻辑回归运算
val viModel = new ValueIndexerModel()
  .setInputCol("职业")
  .setOutputCol("oppo")
  // 如下是导入 ValueIndexerModel 的格式，由此
  // 就一定是学生被编码为 0 工作 1 未知 2
  .setLevels(Array("学生", "工作", "未知"))
val assembler = new VectorAssembler()
  .setInputCols(Array("age", "mobile", "oppo"))
  .setOutputCol("features")
val lr = new LogisticRegression()
  .setMaxIter(10)
  .setRegParam(0.001)
  .setFeatureCol("features")
  .setLabelCol("label")
val pipeline = new Pipeline()
  .setStages(Array(viModel, assembler, lr))

// 训练数据输入管道，得到 model
val model = pipeline.fit(training)

// 测试数据输入 model ，得到结果
model.transform(test)
  .select("id", "probability", "prediction")
  .collect()
  .foreach { case Row(id: Long, prob: Vector, prediction: Double) =>
    println(s"$id --> prob=$prob, prediction=$prediction")
  }
```

那么，问题来了，在输入数据训练（也就是 pipeline 在 fit 时）中， ValueIndexerModel 该如何处理呢？

实际上，并不用在意，因为如果 pipeline 在 fit 时， pipeline 会自动为我们跳过已经训练好的部分，不改变这部分的参数。源代码[spark/ml/Pipeline.scala](https://github.com/apache/spark/blob/5264164a67df498b73facae207eda12ee133be7d/mllib/src/main/scala/org/apache/spark/ml/Pipeline.scala)如下：

```scala
    ...
    val transformers = ListBuffer.empty[Transformer]
    theStages.view.zipWithIndex.foreach { case (stage, index) =>
      if (index <= indexOfLastEstimator) {
        val transformer = stage match {
          case estimator: Estimator[_] =>
            estimator.fit(curDataset)
          case t: Transformer =>
            t  // 在这里
          case _ =>
            throw new IllegalArgumentException(
              s"Does not support stage $stage of type ${stage.getClass}")
        }
        if (index < indexOfLastEstimator) {
          curDataset = transformer.transform(curDataset)
        }
        transformers += transformer
      } else {
        transformers += stage.asInstanceOf[Transformer]
      }
    }

    new PipelineModel(uid, transformers.toArray).setParent(this)
    ...
```

而我们的训练好的模型都是 Transformer 的子类，因此这里生成 PipelineModel 时直接适用了训练好的模型。

参考：
- [https://github.com/microsoft/SynapseML/blob/383cb951811908fe29b85253edfd8dffb9b2241c/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/ValueIndexer.scala](https://github.com/microsoft/SynapseML/blob/383cb951811908fe29b85253edfd8dffb9b2241c/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/ValueIndexer.scala)
- [Add new fitted stage to a exitsting PipelineModel without fitting again](https://stackoverflow.com/a/53269590/17707800)

### Spark 工作总结

### Spark 单元测试

### 高效率 WOE

### Spark 转换多列 LabelEncoder
